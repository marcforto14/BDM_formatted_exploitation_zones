from pyspark.sql import SparkSession
import pyspark.sql.functions as F
from pyspark.sql.functions import col, corr

def generate_KPIs():
    spark = (
        SparkSession.builder 
        .appName("Prediction BDM")
        .config("spark.executor.memory", "4g")
        .config("spark.driver.memory", "2g")
        .config("spark.sql.debug.maxToStringFields", 1000) 
        .getOrCreate()
    )
    # KPI1 - Correlation of rent price and family income per neighborhood

    # Read idealista data
    idealista_data = spark.read.parquet("../exploitation_zone/idealista")

    # Read Neighborhood data and filter for the latest year
    income_data = spark.read.parquet("../exploitation_zone/neighborhood_data")
    latest_year = income_data.select(F.max("year")).collect()[0][0]
    income_data_latest = income_data.filter(F.col("year") == latest_year)
    income_data_latest = income_data_latest.withColumn("neigh_name", F.initcap("neigh_name")) #for neighborhood join later

# Run the KPI generation
generate_KPIs()



